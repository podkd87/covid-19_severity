{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff199fd-8dc6-4929-a7ed-d7809c5d05a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import warnings\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# import math\n",
    "import torch.nn.functional as F\n",
    "# from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import time\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from util import accuracy\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report,\n",
    "                             auc, roc_auc_score,average_precision_score)\n",
    "from training_util_mae import (MyDataset, split, Transformer_park, Transformer_pretrain,\n",
    "                        base_model, base_decoder, hierachy_model, train, validate, weighted_sampling,\n",
    "                              eval_model)\n",
    "import easydict\n",
    "from sklearn.preprocessing import label_binarize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0a494-5869-4e62-b6cf-e754781e81f8",
   "metadata": {},
   "source": [
    "### define model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17cc367-dc81-4c91-8b57-70be5da2cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(args):\n",
    "    b_model = base_model(n_each_base = args.n_each_base,\n",
    "                         mask_on=args.mask_on).cuda(args.cuda_i)\n",
    "    vital_model = Transformer_park(n_each_lab = args.n_each_vital,\n",
    "                                       n_embed = args.n_embed, \n",
    "                                       nhead = args.nhead, \n",
    "                                       nhid = args.nhid, \n",
    "                                       nlayers = args.nlayers, \n",
    "                                       dropout = args.dropout, \n",
    "                                       mask_on = args.mask_on).cuda(args.cuda_i)\n",
    "    lab_model = Transformer_park(n_each_lab = args.n_each_lab,\n",
    "                                     n_embed = args.n_embed, \n",
    "                                     nhead = args.nhead, \n",
    "                                     nhid = args.nhid, \n",
    "                                     nlayers = args.nlayers, \n",
    "                                     dropout = args.dropout, \n",
    "                                     mask_on = args.mask_on ).cuda(args.cuda_i)\n",
    "    decoder_vital = Transformer_pretrain(n_each_lab = args.n_each_vital,\n",
    "                                        n_embed = args.n_embed).cuda(args.cuda_i)\n",
    "    decoder_lab = Transformer_pretrain(n_each_lab = args.n_each_lab,\n",
    "                                       n_embed = args.n_embed).cuda(args.cuda_i)\n",
    "    decoder_base = base_decoder(n_each_base = args.n_each_base).cuda(args.cuda_i)\n",
    "    total_model = hierachy_model(vital_shape = args.vital_shape, \n",
    "                                 lab_shape = args.lab_shape, \n",
    "                                 batch_size =args.batch_size, \n",
    "                                 output_len = args.output_len).cuda(args.cuda_i)\n",
    "    optimizer = optim.Adam([{\"params\":vital_model.parameters()},\n",
    "                            {\"params\":lab_model.parameters()},\n",
    "                            {\"params\":b_model.parameters()},\n",
    "                            {\"params\":decoder_base.parameters()},\n",
    "                            {\"params\":decoder_vital.parameters()},\n",
    "                            {\"params\":decoder_lab.parameters()},\n",
    "                           {\"params\":total_model.parameters()}], \n",
    "                            lr = args.lr_, \n",
    "                            weight_decay = args.weight_decay_)\n",
    "    wandb.watch([b_model, vital_model, lab_model,total_model])   \n",
    "    best_auroc = -np.inf\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(1, args.epochs):\n",
    "        train_loss = train(train_loader, b_model, vital_model, lab_model, decoder_vital,\n",
    "          decoder_lab, decoder_base, total_model, optimizer, \n",
    "                           weight = args.weight, \n",
    "                              masking_value = args.masking_value, \n",
    "                               mae = args.mae, \n",
    "                               masking_ratio = args.masking_ratio,\n",
    "                               i = args.cuda_i)\n",
    "        \n",
    "        val_total_loss, val_o_loss, roc_weight_val = validate(valid_loader, b_model, vital_model,\n",
    "                                                              lab_model, decoder_vital,\n",
    "          decoder_lab, decoder_base, total_model, optimizer, weight = args.weight,\n",
    "                                                                  i = args.cuda_i)\n",
    "        \n",
    "        \n",
    "        if args.metric == \"auroc\" and roc_weight_val >= best_auroc:\n",
    "            filename = save_function(args.save_path, args.kfold_num,\n",
    "                                     b_model, vital_model, lab_model, decoder_vital,\n",
    "          decoder_lab, decoder_base, total_model, optimizer)\n",
    "            epoch_no_improve = 0\n",
    "            best_auroc = roc_weight_val\n",
    "        elif args.metric == \"total_loss\" and val_total_loss<= best_loss :\n",
    "            filename = save_function(args.save_path, args.kfold_num,\n",
    "                                    b_model, vital_model, lab_model, decoder_vital,\n",
    "          decoder_lab, decoder_base, total_model, optimizer)\n",
    "            epoch_no_improve = 0\n",
    "            best_loss = val_total_loss\n",
    "        elif args.metric == \"target_loss\" and val_o_loss<= best_loss :\n",
    "            filename = save_function(args.save_path, args.kfold_num,\n",
    "                                    b_model, vital_model, lab_model, decoder_vital,\n",
    "          decoder_lab, decoder_base, total_model, optimizer)\n",
    "            epoch_no_improve = 0\n",
    "            best_loss = val_o_loss\n",
    "        else:\n",
    "            epoch_no_improve +=1\n",
    "            \n",
    "        ###early stopping\n",
    "        if args.early_stop:\n",
    "            if epoch> args.min_epoch and epoch_no_improve > args.n_epochs_stop:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return filename\n",
    "\n",
    "def save_function(save_path, number, b_model, vital_model, lab_model, decoder_vital,\n",
    "          decoder_lab, decoder_base, total_model, optimizer):\n",
    "    fileuser = [f for f in os.listdir(save_path) \n",
    "                if f.startswith(f\"model{number}_pad_hos{padded_hosday}_emb_{args.n_embed}_\\\n",
    "    hid_{args.nhid}_layer_{args.nlayers}_lr_{args.lr_}_mr{args.masking_ratio}\")]\n",
    "    if fileuser:\n",
    "        if os.path.isfile(save_path+\"/\"+fileuser[0]):\n",
    "            os.remove(save_path+\"/\"+fileuser[0])\n",
    "\n",
    "    filename = save_path+f\"/model{number}_pad_hos{padded_hosday}_emb_{args.n_embed}_\\\n",
    "    hid_{args.nhid}_layer_{args.nlayers}_lr_{args.lr_}_mr{args.masking_ratio}.pt\"\n",
    "    torch.save({\"b_model_dict\":b_model.state_dict(),\n",
    "               \"vital_model_dict\":vital_model.state_dict(),\n",
    "                \"lab_model_dict\":lab_model.state_dict(),\n",
    "                \"decoder_vital_dict\":decoder_vital.state_dict(),\n",
    "               \"decoder_lab_dict\":decoder_lab.state_dict(),\n",
    "                \"decoder_base_dict\":decoder_base.state_dict(),\n",
    "               \"total_model_dict\":total_model.state_dict(),\n",
    "               \"optimizer_dict\":optimizer.state_dict()}, filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759662d6-e4ea-4462-bedc-ba033de993f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_model(args, loaded_model):\n",
    "    b_model = base_model(n_each_base = args.n_each_base,\n",
    "                         mask_on=args.mask_on)\n",
    "    vital_model = Transformer_park(n_each_lab = args.n_each_vital,\n",
    "                                       n_embed = args.n_embed, \n",
    "                                       nhead = args.nhead, \n",
    "                                       nhid = args.nhid, \n",
    "                                       nlayers = args.nlayers, \n",
    "                                       dropout = args.dropout, \n",
    "                                       mask_on = args.mask_on)\n",
    "    lab_model = Transformer_park(n_each_lab = args.n_each_lab,\n",
    "                                     n_embed = args.n_embed, \n",
    "                                     nhead = args.nhead, \n",
    "                                     nhid = args.nhid, \n",
    "                                     nlayers = args.nlayers, \n",
    "                                     dropout = args.dropout, \n",
    "                                     mask_on = args.mask_on )\n",
    "    decoder_vital = Transformer_pretrain(n_each_lab = args.n_each_vital,\n",
    "                                        n_embed = args.n_embed)\n",
    "    decoder_lab = Transformer_pretrain(n_each_lab = args.n_each_lab,\n",
    "                                       n_embed = args.n_embed)\n",
    "    decoder_base = base_decoder(n_each_base = args.n_each_base)\n",
    "    total_model = hierachy_model(vital_shape = args.vital_shape, \n",
    "                                 lab_shape = args.lab_shape, \n",
    "                                 batch_size =args.test_batchsize, \n",
    "                                 output_len = args.output_len)\n",
    "\n",
    "    vital_model.load_state_dict(loaded_model['vital_model_dict'])\n",
    "    lab_model.load_state_dict(loaded_model['lab_model_dict'])\n",
    "    b_model.load_state_dict(loaded_model['b_model_dict'])\n",
    "    total_model.load_state_dict(loaded_model['total_model_dict'])\n",
    "    decoder_vital.load_state_dict(loaded_model['decoder_vital_dict'])\n",
    "    decoder_lab.load_state_dict(loaded_model['decoder_lab_dict'])\n",
    "    decoder_base.load_state_dict(loaded_model['decoder_base_dict'])\n",
    "    \n",
    "    vital_model.eval()\n",
    "    lab_model.eval()\n",
    "    b_model.eval()\n",
    "    total_model.eval()\n",
    "    decoder_vital.eval()\n",
    "    decoder_lab.eval()\n",
    "    decoder_base.eval()\n",
    "\n",
    "    return vital_model, lab_model, b_model, total_model, decoder_vital, decoder_lab, decoder_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054a2c70-fe7c-4d6f-afc7-3e6348007aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_outcome(test_loader, vital_model, lab_model, b_model, total_model, \n",
    "                decoder_vital, decoder_lab, decoder_base):\n",
    "    for batch, batch_data in enumerate(test_loader):\n",
    "        vital_set = batch_data[0]\n",
    "        lab_set = batch_data[1]\n",
    "        baseline_set = batch_data[2]\n",
    "        each_att_vital_set = batch_data[3]\n",
    "        each_att_lab_set = batch_data[4]\n",
    "        each_att_base_set = batch_data[5]\n",
    "        att_vital_set = batch_data[6]\n",
    "        att_lab_set = batch_data[7]\n",
    "        outcome = batch_data[8]\n",
    "        outcome = outcome.type(torch.LongTensor)\n",
    "\n",
    "        vital_tensor = vital_model(vital_set.transpose(0,1), att_vital_set,\n",
    "                                   each_mask = each_att_vital_set.transpose(0,1))\n",
    "        lab_tensor = lab_model(lab_set.transpose(0,1), att_lab_set,\n",
    "                               each_mask = each_att_lab_set.transpose(0,1))\n",
    "        base_tensor = b_model(baseline_set, each_att_base_set)\n",
    "\n",
    "        vital_out = decoder_vital(vital_tensor)  #MLM용도\n",
    "        lab_out = decoder_lab(lab_tensor)    #MLM 용도\n",
    "        base_out = decoder_base(base_tensor) #MLM 용도\n",
    "\n",
    "        #compute loss\n",
    "        result = total_model(vital_tensor, lab_tensor, base_tensor)\n",
    "        \n",
    "        if batch==0:\n",
    "            result_t = result.cpu().detach()\n",
    "            outcome_t =outcome.cpu().detach()\n",
    "        else:\n",
    "            result_t = torch.cat([result.cpu(), result_t],axis=0).detach()\n",
    "            outcome_t = torch.cat([outcome.cpu(), outcome_t],axis=0).detach()\n",
    "            \n",
    "    return result_t, outcome_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd3e04f-bb2e-41a4-b5f0-10ff8e877c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc_auprc(predicted, outcome):\n",
    "    val_acc1, val_acc2 = accuracy(predicted, outcome, topk=(1,2))\n",
    "    soft = nn.Softmax(dim=1)\n",
    "    s_predicted = soft(predicted).detach().numpy()\n",
    "    outcome_onehot = label_binarize(outcome, classes=[0,1,2])\n",
    "\n",
    "    avscore = average_precision_score(outcome_onehot, s_predicted, average='weighted')\n",
    "    val_acc1 = val_acc1.item()\n",
    "    roc_weight_val = roc_auc_score(outcome_onehot, s_predicted, \n",
    "                                   multi_class= 'ovr', average = 'weighted')\n",
    "\n",
    "    return val_acc1, roc_weight_val, avscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136acaf9-0650-4fbf-ba7d-efbb4536fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\"masking_value\": 0, #masking value selection \n",
    "                          \"batch_size\": 1000, #number of each batch \n",
    "                          \"file_name\": \"../whole_3data0630_o2_idscale.txt\",\n",
    "                          \"min_epoch\": 200, #minimum epoch for training\n",
    "                          \"n_epochs_stop\": 10, #stop epoch after nth training without performance gain\n",
    "                          \"epochs\": 1000, #maximum epoch \n",
    "                          \"early_stop\": True, #setting of early stopping\n",
    "                          \"nhead\": 4,  #transformer number of head\n",
    "                          \"n_embed\": 160, #transformer number of embedding layer\n",
    "                          \"nhid\": 320, #transformer number of hidden layer\n",
    "                          \"nlayers\": 4, #transformenr encoder layer number\n",
    "                          \"dropout\": 0.2, #drop out \n",
    "                          \"lr_\": 5e-5, #learning rate\n",
    "                          \"weight_decay_\": 1e-4, #weight decay\n",
    "                          \"output_len\": 3, #number of output category number\n",
    "                          \"prior_d\":0, #prediction day 0 or day 1 or day 2\n",
    "                          \"weight\": 1.0, #weight of decoder loss\n",
    "                          \"mae\": False, #use of masked autoencoder \n",
    "                          \"mask_on\":True, #use of masking layer\n",
    "                          \"masking_ratio\": 0., #MAE ratio when it used\n",
    "                          \"metric\": 'total_loss', #early stopping reference \n",
    "                          \"cuda_i\" : 1, #cuda device number\n",
    "                            \"save_path\" : \"./save_confidence_interval\" #save folder name \n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b73539-fa2e-4a39-a072-391d38aadf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape과 관련된 hyperparameters\n",
    "\n",
    "padded_hosday_list = [2,4,6,8,10,12,14,16,18,20]\n",
    "if not os.path.isdir(args.save_path):\n",
    "    os.makedirs(args.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecddfa-4f7f-46bb-93b6-c78e675ff163",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:04<00:00, 507.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.2385096549987793 stack complete\n",
      "time: 0.0029115676879882812 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 641.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.265444278717041 stack complete\n",
      "time: 0.0007102489471435547 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 499.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.43497753143310547 stack complete\n",
      "time: 0.0015921592712402344 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpodkd\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_074747-ye2sans7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/ye2sans7\" target=\"_blank\">young-deluge-88</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:04<00:00, 537.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.070150375366211 stack complete\n",
      "time: 0.0029265880584716797 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 616.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.28205347061157227 stack complete\n",
      "time: 0.0014150142669677734 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 547.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.3023815155029297 stack complete\n",
      "time: 0.0012483596801757812 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ye2sans7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▃▅▆▆▇▇▇▇▇▇████▇▇█▇▇█▇█████▇▇██████▇███▇</td></tr><tr><td>auroc_weight</td><td>▁▃▅▆▆▇▇▇▇▇▇███████▇█████████████████████</td></tr><tr><td>top1 accuracy</td><td>▁▂▅▆▆▆▇▇▇▇▇▇████▇█▇▇██▇█▇███▇▇▇▇▇▇▇▇█▇██</td></tr><tr><td>train outcome loss</td><td>█▆▅▄▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▅▃▂▂▂▂▂▁▂▁▁▁▁▁▂▂▁▃▂▁▂▂▂▂▂▂▃▃▂▃▃▂▃▄▄▂▄▃▄</td></tr><tr><td>val total loss</td><td>█▅▃▂▂▂▂▂▁▂▁▁▁▁▁▂▂▁▃▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.89899</td></tr><tr><td>auroc_weight</td><td>0.89783</td></tr><tr><td>top1 accuracy</td><td>74.2625</td></tr><tr><td>train outcome loss</td><td>0.37969</td></tr><tr><td>train total loss</td><td>0.40986</td></tr><tr><td>val outcome loss</td><td>0.77056</td></tr><tr><td>val total loss</td><td>0.79341</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">young-deluge-88</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/ye2sans7\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/ye2sans7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_074747-ye2sans7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ye2sans7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_075610-2ibn0bi6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/2ibn0bi6\" target=\"_blank\">dandy-fog-89</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:04<00:00, 503.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.4508543014526367 stack complete\n",
      "time: 0.0036242008209228516 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 616.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.3926839828491211 stack complete\n",
      "time: 0.0022046566009521484 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 501.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.39783740043640137 stack complete\n",
      "time: 0.0015521049499511719 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ibn0bi6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▃▅▇▇███▇█▇▇▇▇▇█▇▇███▇█▇▇▇████▇█▇█▇▇▇███</td></tr><tr><td>auroc_weight</td><td>▁▂▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇█▇████▇██▇▇█████</td></tr><tr><td>top1 accuracy</td><td>▁▄▅▆▆▇▆▇▇▇▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train outcome loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▄▃▂▁▁▁▁▁▁▂▂▂▃▃▂▃▃▃▂▃▄▃▄▄▄▄▃▄▃▄▄▅▄▅▅▅▄▃▄</td></tr><tr><td>val total loss</td><td>█▄▃▂▁▁▁▁▁▁▂▂▁▂▂▂▂▂▂▂▂▃▂▃▃▃▃▂▃▃▃▃▃▃▄▄▄▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.88781</td></tr><tr><td>auroc_weight</td><td>0.89736</td></tr><tr><td>top1 accuracy</td><td>77.3625</td></tr><tr><td>train outcome loss</td><td>0.3941</td></tr><tr><td>train total loss</td><td>0.42504</td></tr><tr><td>val outcome loss</td><td>0.86793</td></tr><tr><td>val total loss</td><td>0.89173</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dandy-fog-89</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/2ibn0bi6\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/2ibn0bi6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_075610-2ibn0bi6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2ibn0bi6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_080511-22uak5xs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/22uak5xs\" target=\"_blank\">smooth-lion-90</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:04<00:00, 521.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.0943362712860107 stack complete\n",
      "time: 0.0029573440551757812 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 539.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.28324341773986816 stack complete\n",
      "time: 0.0015037059783935547 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 526.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.297443151473999 stack complete\n",
      "time: 0.0014719963073730469 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:22uak5xs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▃▄▅▅▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>auroc_weight</td><td>▁▃▄▅▅▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>top1 accuracy</td><td>▁▂▃▄▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇███▇██▇██████████████</td></tr><tr><td>train outcome loss</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▅▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val total loss</td><td>█▅▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.92343</td></tr><tr><td>auroc_weight</td><td>0.91994</td></tr><tr><td>top1 accuracy</td><td>81.05</td></tr><tr><td>train outcome loss</td><td>0.39878</td></tr><tr><td>train total loss</td><td>0.42905</td></tr><tr><td>val outcome loss</td><td>0.62801</td></tr><tr><td>val total loss</td><td>0.65268</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smooth-lion-90</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/22uak5xs\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/22uak5xs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_080511-22uak5xs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:22uak5xs). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_081404-1xc6rwsc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/1xc6rwsc\" target=\"_blank\">fallen-thunder-91</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:04<00:00, 506.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.087808609008789 stack complete\n",
      "time: 0.003065824508666992 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 607.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.27863550186157227 stack complete\n",
      "time: 0.0015964508056640625 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 532.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.30098986625671387 stack complete\n",
      "time: 0.0017347335815429688 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1xc6rwsc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▃▅▆▇▆▇▇▇▇███▇▇▇██▇███████████▇▇▇██▇████</td></tr><tr><td>auroc_weight</td><td>▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████▇███▇████</td></tr><tr><td>top1 accuracy</td><td>▁▃▄▄▅▅▆▆▇▆▇▇▇▇▇▇▇█▇███▇████████▇███▇███▇</td></tr><tr><td>train outcome loss</td><td>█▆▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▄▃▃▂▂▂▁▁▂▁▁▁▂▂▂▂▂▂▂▃▂▂▂▂▃▂▃▂▂▄▄▄▃▄▅▄▃▂▃</td></tr><tr><td>val total loss</td><td>█▄▃▂▂▂▂▁▁▂▁▁▁▂▂▂▁▁▂▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.8914</td></tr><tr><td>auroc_weight</td><td>0.89495</td></tr><tr><td>top1 accuracy</td><td>76.2375</td></tr><tr><td>train outcome loss</td><td>0.40171</td></tr><tr><td>train total loss</td><td>0.43197</td></tr><tr><td>val outcome loss</td><td>0.80899</td></tr><tr><td>val total loss</td><td>0.833</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fallen-thunder-91</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/1xc6rwsc\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/1xc6rwsc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_081404-1xc6rwsc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1xc6rwsc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_082319-kihpp1k5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/kihpp1k5\" target=\"_blank\">comic-spaceship-92</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:05<00:00, 447.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.3382277488708496 stack complete\n",
      "time: 0.0030279159545898438 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 623.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.30743980407714844 stack complete\n",
      "time: 0.0016782283782958984 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 504.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.3475029468536377 stack complete\n",
      "time: 0.0015532970428466797 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:kihpp1k5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▄▆▇▇▇██████████████████████████████████</td></tr><tr><td>auroc_weight</td><td>▁▃▅▆▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>top1 accuracy</td><td>▁▃▅▆▆▇▇▇▇▇▇▇█▇▇▇██▇█▇█████████████████▇█</td></tr><tr><td>train outcome loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▂▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▃</td></tr><tr><td>val total loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▂▂▁▂▂▂▂▂▂▃▂▂▂▂▃▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.8966</td></tr><tr><td>auroc_weight</td><td>0.9022</td></tr><tr><td>top1 accuracy</td><td>76.7</td></tr><tr><td>train outcome loss</td><td>0.39504</td></tr><tr><td>train total loss</td><td>0.42513</td></tr><tr><td>val outcome loss</td><td>0.79346</td></tr><tr><td>val total loss</td><td>0.81767</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comic-spaceship-92</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/kihpp1k5\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/kihpp1k5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_082319-kihpp1k5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:kihpp1k5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_083242-3e1r1ygc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/3e1r1ygc\" target=\"_blank\">solar-vortex-93</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:04<00:00, 514.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.2635819911956787 stack complete\n",
      "time: 0.0032625198364257812 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 522.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.3398880958557129 stack complete\n",
      "time: 0.0016951560974121094 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 517.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.3814122676849365 stack complete\n",
      "time: 0.0017824172973632812 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3e1r1ygc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▅▆▆▇▇▇▇█▇▇▇▇█████████████████████▇█████</td></tr><tr><td>auroc_weight</td><td>▁▅▆▆▇▇▇▇█▇▇▇████████████████████████████</td></tr><tr><td>top1 accuracy</td><td>▁▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇█▇▇▇▇▇████</td></tr><tr><td>train outcome loss</td><td>█▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▄▃▃▂▁▂▁▁▁▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▃▂▂▃▂▂▂▂▃▃▃▂▂▃</td></tr><tr><td>val total loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▁▂▂▁▃▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.9268</td></tr><tr><td>auroc_weight</td><td>0.92793</td></tr><tr><td>top1 accuracy</td><td>81.4125</td></tr><tr><td>train outcome loss</td><td>0.31117</td></tr><tr><td>train total loss</td><td>0.3414</td></tr><tr><td>val outcome loss</td><td>0.68206</td></tr><tr><td>val total loss</td><td>0.7048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-vortex-93</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/3e1r1ygc\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/3e1r1ygc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_083242-3e1r1ygc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3e1r1ygc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_084230-ndrdag2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/ndrdag2c\" target=\"_blank\">kind-plant-94</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:05<00:00, 462.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1989874839782715 stack complete\n",
      "time: 0.003300905227661133 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 607.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.30926036834716797 stack complete\n",
      "time: 0.0015840530395507812 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 506.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.3320956230163574 stack complete\n",
      "time: 0.001645803451538086 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ndrdag2c) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▅▇▇▇███████████████████████████████████</td></tr><tr><td>auroc_weight</td><td>▁▅▇▇▇▇▇▇█▇▇█████████████████████████████</td></tr><tr><td>top1 accuracy</td><td>▁▄▆▆▆▆▇▇▇▇▇▆▇▇▇▆▇▇█▇▇█▇▇█▇▇▇▇█▇▇▇██▇▇▇▇▇</td></tr><tr><td>train outcome loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▄▂▂▁▁▁▁▁▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▃▂▃▃▂▃▃▃▃▄▄▃</td></tr><tr><td>val total loss</td><td>█▄▂▂▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.91829</td></tr><tr><td>auroc_weight</td><td>0.92588</td></tr><tr><td>top1 accuracy</td><td>79.4875</td></tr><tr><td>train outcome loss</td><td>0.32906</td></tr><tr><td>train total loss</td><td>0.3591</td></tr><tr><td>val outcome loss</td><td>0.72943</td></tr><tr><td>val total loss</td><td>0.75316</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">kind-plant-94</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/ndrdag2c\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/ndrdag2c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_084230-ndrdag2c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ndrdag2c). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_085207-k06y2oq4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/k06y2oq4\" target=\"_blank\">spring-sound-95</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:05<00:00, 476.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.274221420288086 stack complete\n",
      "time: 0.0031652450561523438 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 511.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.4551715850830078 stack complete\n",
      "time: 0.0026504993438720703 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 576.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.4877197742462158 stack complete\n",
      "time: 0.0023469924926757812 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:k06y2oq4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▄▆▆▇▇▇█████████████████████████████████</td></tr><tr><td>auroc_weight</td><td>▁▄▆▆▇▇▇█████████████████████████████████</td></tr><tr><td>top1 accuracy</td><td>▁▃▅▆▆▇▇▇█▇█▇████████████████████████████</td></tr><tr><td>train outcome loss</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val total loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▂▁▂▁▁▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.943</td></tr><tr><td>auroc_weight</td><td>0.94283</td></tr><tr><td>top1 accuracy</td><td>83.7875</td></tr><tr><td>train outcome loss</td><td>0.33887</td></tr><tr><td>train total loss</td><td>0.3694</td></tr><tr><td>val outcome loss</td><td>0.53481</td></tr><tr><td>val total loss</td><td>0.55888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-sound-95</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/k06y2oq4\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/k06y2oq4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_085207-k06y2oq4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:k06y2oq4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_090149-2yw3j2z1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/2yw3j2z1\" target=\"_blank\">cool-valley-96</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401/2401 [00:04<00:00, 481.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.7637836933135986 stack complete\n",
      "time: 0.00425410270690918 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 477.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.49842238426208496 stack complete\n",
      "time: 0.002262115478515625 dataset completely loaded\n",
      "whole data is completely loaded\n",
      "load completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 801/801 [00:01<00:00, 482.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.47652673721313477 stack complete\n",
      "time: 0.0021517276763916016 dataset completely loaded\n",
      "whole data is completely loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2yw3j2z1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>▁▅▆▆▇▇▇▇▇▇▇██████████▇█████▇████████▇███</td></tr><tr><td>auroc_weight</td><td>▁▅▆▆▇▇▇▇▇▇▇███▇██████▇██████████████████</td></tr><tr><td>top1 accuracy</td><td>▁▅▅▅▆▆▇▇▇▇▇▇▇▇▇██████▇██████████████████</td></tr><tr><td>train outcome loss</td><td>█▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train total loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val outcome loss</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▃▂▁▃▂▂▃▃▃▃▃▃▄▃▄▃</td></tr><tr><td>val total loss</td><td>█▄▃▃▂▂▂▂▂▂▁▁▁▁▂▁▂▂▂▁▂▂▁▂▂▂▁▂▂▂▃▂▂▃▂▂▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>auroc_micro</td><td>0.91729</td></tr><tr><td>auroc_weight</td><td>0.92409</td></tr><tr><td>top1 accuracy</td><td>79.5625</td></tr><tr><td>train outcome loss</td><td>0.3413</td></tr><tr><td>train total loss</td><td>0.37179</td></tr><tr><td>val outcome loss</td><td>0.73215</td></tr><tr><td>val total loss</td><td>0.75513</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cool-valley-96</strong>: <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/2yw3j2z1\" target=\"_blank\">https://wandb.ai/podkd/brmh0728_3_today_o2/runs/2yw3j2z1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220802_090149-2yw3j2z1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2yw3j2z1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/brmh/code/wandb/run-20220802_091149-1dwwk99g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2/runs/1dwwk99g\" target=\"_blank\">volcanic-eon-97</a></strong> to <a href=\"https://wandb.ai/podkd/brmh0728_3_today_o2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MLM 시작전 모델 loss \n",
    "performance = dict()\n",
    "accu_list = list()\n",
    "auroc_list = list()\n",
    "auprc_list = list()\n",
    "padd_list = list()\n",
    "for padded_hosday in padded_hosday_list:\n",
    "\n",
    "    for number in range(5):\n",
    "        args.kfold_num = number\n",
    "        train_set, valid_set, test_set = split(args.file_name, random_s=number) \n",
    "\n",
    "        train_dataset = MyDataset(args.masking_value, train_set, \n",
    "                                  padded_hosday, data_pr = 1,prior_d=args.prior_d)\n",
    "        valid_dataset = MyDataset(args.masking_value, valid_set, \n",
    "                                  padded_hosday, data_pr = 1, prior_d=args.prior_d)\n",
    "        test_dataset = MyDataset(args.masking_value, test_set, \n",
    "                                 padded_hosday, data_pr = 1, prior_d=args.prior_d)\n",
    "\n",
    "        train_loader, valid_loader = weighted_sampling(train_dataset, valid_dataset, \n",
    "                                                       batch_size = args.batch_size)\n",
    "        \n",
    "        args.n_each_vital = train_set[0][2].shape[-1]\n",
    "        args.n_each_lab = train_set[0][1].shape[-1]\n",
    "        args.n_each_base = train_set[0][0].shape[-1]\n",
    "\n",
    "        args.vital_shape = padded_hosday*3*args.n_embed\n",
    "        args.lab_shape = padded_hosday*args.n_embed\n",
    "        args.test_batchsize = len(test_dataset)\n",
    "        wandb.init(project=\"brmh0728_3_today_o2\", entity='podkd', \n",
    "                   tags=[f'padding day:{padded_hosday}'])\n",
    "        wandb.run.name = f\"model_e:pad_day_{padded_hosday}_number{number}\"\n",
    "\n",
    "        filename = model_train(args)\n",
    "        loaded_model_0 = torch.load(filename)\n",
    "        \n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset),\n",
    "                                     shuffle=False, drop_last=True)\n",
    "        load_0 = loading_model(args, loaded_model_0)\n",
    "        predicted, outcome = predicted_outcome(test_loader, load_0[0], load_0[1],\n",
    "                                       load_0[2],load_0[3], load_0[4], load_0[5], load_0[6])\n",
    "        \n",
    "        accura1, auroc_test, auprc_test = auroc_auprc(predicted, outcome)\n",
    "        accu_list.append(accura1)\n",
    "        auroc_list.append(auroc_test)\n",
    "        auprc_list.append(auprc_test)\n",
    "        padd_list.append(padded_hosday)\n",
    "\n",
    "performance[\"accuracy\"] = accu_list\n",
    "performance[\"auroc\"] = auroc_list\n",
    "performance[\"auprc\"] = auprc_list\n",
    "performance[\"padding_day\"] = padd_list\n",
    "    \n",
    "performance = pd.DataFrame(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452a39d-0776-46d4-9654-0d5930a0ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.to_csv(\"./performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14b91ae-df9e-4508-a92e-c1d7b1ac4193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>padding_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>75.687080</td>\n",
       "      <td>0.899842</td>\n",
       "      <td>0.875173</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73.708069</td>\n",
       "      <td>0.894894</td>\n",
       "      <td>0.868742</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>79.292404</td>\n",
       "      <td>0.915219</td>\n",
       "      <td>0.899777</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>74.401070</td>\n",
       "      <td>0.887667</td>\n",
       "      <td>0.866931</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>75.101028</td>\n",
       "      <td>0.894946</td>\n",
       "      <td>0.875554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>79.341988</td>\n",
       "      <td>0.922428</td>\n",
       "      <td>0.899201</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>76.838776</td>\n",
       "      <td>0.906892</td>\n",
       "      <td>0.885279</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>81.234375</td>\n",
       "      <td>0.926430</td>\n",
       "      <td>0.905338</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>79.321434</td>\n",
       "      <td>0.919866</td>\n",
       "      <td>0.896227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>77.535744</td>\n",
       "      <td>0.909147</td>\n",
       "      <td>0.879303</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>83.389755</td>\n",
       "      <td>0.949518</td>\n",
       "      <td>0.923307</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>82.728203</td>\n",
       "      <td>0.938935</td>\n",
       "      <td>0.912023</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>82.810028</td>\n",
       "      <td>0.949590</td>\n",
       "      <td>0.924312</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>80.626030</td>\n",
       "      <td>0.934277</td>\n",
       "      <td>0.905315</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>84.123138</td>\n",
       "      <td>0.948521</td>\n",
       "      <td>0.926108</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>87.292755</td>\n",
       "      <td>0.968525</td>\n",
       "      <td>0.947693</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>81.072838</td>\n",
       "      <td>0.951118</td>\n",
       "      <td>0.917125</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>83.515747</td>\n",
       "      <td>0.951516</td>\n",
       "      <td>0.920735</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>86.601051</td>\n",
       "      <td>0.963198</td>\n",
       "      <td>0.942476</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>85.255478</td>\n",
       "      <td>0.958281</td>\n",
       "      <td>0.934259</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>87.875732</td>\n",
       "      <td>0.961749</td>\n",
       "      <td>0.946327</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>87.078461</td>\n",
       "      <td>0.966499</td>\n",
       "      <td>0.948258</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>86.367088</td>\n",
       "      <td>0.962472</td>\n",
       "      <td>0.937253</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>85.202492</td>\n",
       "      <td>0.957205</td>\n",
       "      <td>0.928570</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>86.343010</td>\n",
       "      <td>0.961011</td>\n",
       "      <td>0.938550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>88.395088</td>\n",
       "      <td>0.975990</td>\n",
       "      <td>0.955636</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>87.135277</td>\n",
       "      <td>0.969988</td>\n",
       "      <td>0.949353</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>88.170456</td>\n",
       "      <td>0.973580</td>\n",
       "      <td>0.953775</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>87.737732</td>\n",
       "      <td>0.962680</td>\n",
       "      <td>0.949313</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>88.905045</td>\n",
       "      <td>0.976981</td>\n",
       "      <td>0.957703</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>91.527313</td>\n",
       "      <td>0.976890</td>\n",
       "      <td>0.965763</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>87.658264</td>\n",
       "      <td>0.962881</td>\n",
       "      <td>0.944511</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>92.491928</td>\n",
       "      <td>0.980752</td>\n",
       "      <td>0.967875</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>85.321808</td>\n",
       "      <td>0.952777</td>\n",
       "      <td>0.920188</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>87.253120</td>\n",
       "      <td>0.968268</td>\n",
       "      <td>0.943103</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>89.816902</td>\n",
       "      <td>0.977002</td>\n",
       "      <td>0.960704</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>90.827934</td>\n",
       "      <td>0.979413</td>\n",
       "      <td>0.962166</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>89.741859</td>\n",
       "      <td>0.976704</td>\n",
       "      <td>0.956380</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>92.387466</td>\n",
       "      <td>0.981159</td>\n",
       "      <td>0.969524</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>89.114738</td>\n",
       "      <td>0.970860</td>\n",
       "      <td>0.954345</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>89.469048</td>\n",
       "      <td>0.975642</td>\n",
       "      <td>0.954725</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>85.008537</td>\n",
       "      <td>0.964822</td>\n",
       "      <td>0.937139</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>90.312462</td>\n",
       "      <td>0.977121</td>\n",
       "      <td>0.958796</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>89.607574</td>\n",
       "      <td>0.975383</td>\n",
       "      <td>0.957883</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>89.322227</td>\n",
       "      <td>0.977517</td>\n",
       "      <td>0.956511</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>89.233910</td>\n",
       "      <td>0.976965</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>87.903404</td>\n",
       "      <td>0.971296</td>\n",
       "      <td>0.948217</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>88.888893</td>\n",
       "      <td>0.976351</td>\n",
       "      <td>0.953618</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>90.733635</td>\n",
       "      <td>0.980817</td>\n",
       "      <td>0.969272</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>89.910812</td>\n",
       "      <td>0.979450</td>\n",
       "      <td>0.959161</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   accuracy     auroc     auprc  padding_day\n",
       "0            0  75.687080  0.899842  0.875173            2\n",
       "1            1  73.708069  0.894894  0.868742            2\n",
       "2            2  79.292404  0.915219  0.899777            2\n",
       "3            3  74.401070  0.887667  0.866931            2\n",
       "4            4  75.101028  0.894946  0.875554            2\n",
       "5            5  79.341988  0.922428  0.899201            4\n",
       "6            6  76.838776  0.906892  0.885279            4\n",
       "7            7  81.234375  0.926430  0.905338            4\n",
       "8            8  79.321434  0.919866  0.896227            4\n",
       "9            9  77.535744  0.909147  0.879303            4\n",
       "10          10  83.389755  0.949518  0.923307            6\n",
       "11          11  82.728203  0.938935  0.912023            6\n",
       "12          12  82.810028  0.949590  0.924312            6\n",
       "13          13  80.626030  0.934277  0.905315            6\n",
       "14          14  84.123138  0.948521  0.926108            6\n",
       "15          15  87.292755  0.968525  0.947693            8\n",
       "16          16  81.072838  0.951118  0.917125            8\n",
       "17          17  83.515747  0.951516  0.920735            8\n",
       "18          18  86.601051  0.963198  0.942476            8\n",
       "19          19  85.255478  0.958281  0.934259            8\n",
       "20          20  87.875732  0.961749  0.946327           10\n",
       "21          21  87.078461  0.966499  0.948258           10\n",
       "22          22  86.367088  0.962472  0.937253           10\n",
       "23          23  85.202492  0.957205  0.928570           10\n",
       "24          24  86.343010  0.961011  0.938550           10\n",
       "25          25  88.395088  0.975990  0.955636           12\n",
       "26          26  87.135277  0.969988  0.949353           12\n",
       "27          27  88.170456  0.973580  0.953775           12\n",
       "28          28  87.737732  0.962680  0.949313           12\n",
       "29          29  88.905045  0.976981  0.957703           12\n",
       "30          30  91.527313  0.976890  0.965763           14\n",
       "31          31  87.658264  0.962881  0.944511           14\n",
       "32          32  92.491928  0.980752  0.967875           14\n",
       "33          33  85.321808  0.952777  0.920188           14\n",
       "34          34  87.253120  0.968268  0.943103           14\n",
       "35          35  89.816902  0.977002  0.960704           16\n",
       "36          36  90.827934  0.979413  0.962166           16\n",
       "37          37  89.741859  0.976704  0.956380           16\n",
       "38          38  92.387466  0.981159  0.969524           16\n",
       "39          39  89.114738  0.970860  0.954345           16\n",
       "40          40  89.469048  0.975642  0.954725           18\n",
       "41          41  85.008537  0.964822  0.937139           18\n",
       "42          42  90.312462  0.977121  0.958796           18\n",
       "43          43  89.607574  0.975383  0.957883           18\n",
       "44          44  89.322227  0.977517  0.956511           18\n",
       "45          45  89.233910  0.976965  0.955465           20\n",
       "46          46  87.903404  0.971296  0.948217           20\n",
       "47          47  88.888893  0.976351  0.953618           20\n",
       "48          48  90.733635  0.980817  0.969272           20\n",
       "49          49  89.910812  0.979450  0.959161           20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2db6c-9886-498b-b816-81c93496a017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_park)",
   "language": "python",
   "name": "conda_park"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
